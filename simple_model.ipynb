{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMZS1dHJebRqO2khadR2AG6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rda12345/Dam-recognition-classification/blob/main/simple_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lagl4TeOFRv2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "if not os.path.exists('./outputs'):\n",
        "  os.mkdir('./outputs')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Global parameters\n",
        "\n",
        "# If USE_CUDA = True, computation will be done using GPU\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "\n",
        "DATASET_PATH = './'\n",
        "BATCH_SIZE = # number of images used to evaluate the gradient in a single step\n",
        "EPOCHS = # number of cycles through the whole data\n",
        "LEARNING_RATE = #"
      ],
      "metadata": {
        "id": "auniWMCtYHHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OIka8P60TZxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data sets and data loaders"
      ],
      "metadata": {
        "id": "wUZvv8UBSCJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Image example and corresponding label"
      ],
      "metadata": {
        "id": "c1PUTftuThal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining architecture"
      ],
      "metadata": {
        "id": "1Irwv40-dMja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN,self).__init__()\n",
        "\n",
        "    # block 1\n",
        "    self.cnn1 = nn.Conv2d(in_channels=, out_channels=, kernel_size=3)   # stride=1, padding=0 are the defult\n",
        "    # self.batchnorm1 = nn.BatchNorm2d()\n",
        "    self.relu = nn.ReLU()\n",
        "    self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
        "    self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "    # block 2\n",
        "    self.cnn2 = nn.Conv2d(in_channels=, out_channels=, kernel_size=3)\n",
        "    # self.batchnorm2 = nn.BatchNorm2d()\n",
        "    self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
        "    self.dropout = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "    # head\n",
        "    self.fc1 = nn.Linear(in_channels=C*H*W, out_channels=)   # the input is flattened\n",
        "    self.fc2 = nn.Linear(in_channel= , out_channel)\n",
        "\n",
        "  def forward(self,x)\n",
        "    # block 1\n",
        "    x = self.cnn1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.maxpoo1(x)\n",
        "    x = self.dropout(x)\n",
        "\n",
        "    # block 2\n",
        "    x = self.cnn2(x)\n",
        "    x = self.maxpool2(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.dropout(x)\n",
        "\n",
        "    # head\n",
        "    x = x.view(x.size(0), -1)\n",
        "    x = self.fc1(x)\n",
        "    x = self.dropout(x)\n",
        "    x = self.fc2(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "w5BD1aTmTv-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initiate models"
      ],
      "metadata": {
        "id": "Q1MW5K6Zc4hv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNN()\n",
        "if USE_CUDA:\n",
        "  model = model.cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.adam(model.parameters())\n",
        "???\n",
        "#optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "schedular = ????"
      ],
      "metadata": {
        "id": "IHq7c7ROfjhk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "R3RHq852fqt0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NOT AT ALL COMPLETE\n",
        "iter_loss = 0.0\n",
        "model.train()   # put the network into training mode\n",
        "\n",
        "if USE_CUDA:\n",
        "  data = data.cuda()\n",
        "  labels = labels.cuda()\n",
        "\n",
        "\n",
        "optimizer.zero_grad()  # clear old gradients\n",
        "predictions = model(data) # forward pass\n",
        "loss = criterion(predictions, labels)  # evaluate loss\n",
        "iter_loss += loss.item()  # accumulated loss\n",
        "loss.backward()   # backpropagation: accumulate grads in .grad\n",
        "optimizer.step()  # update wieghts using grads"
      ],
      "metadata": {
        "id": "RYBD0v7xfunY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "hwIhQmc-ij3c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()  # put the network into evaluation mode\n",
        "\n",
        "if USE_CUDA:\n",
        "  data = data.cuda()\n",
        "  labels = labels.cuda()\n",
        "\n",
        "\n",
        "optimizer.zero_grad()  # clear old gradients\n",
        "predictions = model(data) # forward pass\n",
        "loss = criterion(predictions, labels)  # evaluate loss\n",
        "iter_loss += loss.item()  # accumulated loss\n",
        "loss.backward()   # backpropagation: accumulate grads in .grad\n",
        "optimizer.step()  # update wieghts using grads\n",
        "\n",
        "\n",
        "# Plot and save\n",
        "plt.figure(figsize=)\n",
        "plt.clf() ???\n",
        "plt.plot(epochs, train_loss, label='Train')\n",
        "plt.plot(epochs, train_loss, label='Test')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.title('Cross entropy loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.savefig(...)\n",
        "\n",
        "\n",
        "plt.figure(figsize=)\n",
        "plt.clf() ???\n",
        "plt.plot(epochs, train_accuracy, label='Train')\n",
        "plt.plot(epochs, train_accuracy, label='Test')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.savefig(...)"
      ],
      "metadata": {
        "id": "-4XYXrcRimOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results"
      ],
      "metadata": {
        "id": "_Z-Xc0Aej-8O"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JbnXuFVokCA-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}