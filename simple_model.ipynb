{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNMM929kj59QDC5Di0QoKtr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rda12345/Dam-recognition-classification/blob/main/simple_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Overview\n",
        "\n",
        "The file contains a simple convolutional neural network for ....\n",
        "\n",
        "The convnet is trained on ...\n"
      ],
      "metadata": {
        "id": "l_TMPdbckwq4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j3or0LF2lQV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lagl4TeOFRv2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Import torch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "#import torch.nn.functional F\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "# Orginize outputs\n",
        "#if not os.path.exists('./outputs'):\n",
        "  #os.mkdir('./outputs')\n",
        "\n",
        "# Check that we are using GPU, if not switch runtimes\n",
        "# using Runtime > Change Runtime Type > GPU\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "\n",
        "  # IMPORTANT: cudnn will benchmark different algos. for convolution operations\n",
        "  # and select the on that performs the best for the hardwhare and input size.\n",
        "  # It is usefull when the input sizes are fixed or static during training and inference.\n",
        "  # It isn't benificial when the input sizes change, which would force cudnn to rebenchmark.\n",
        "  #cudnn.benchmark = True\n",
        "\n",
        "else:\n",
        "  raise ValueError(\"GPU is not available. Change Colab runtime\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Global parameters\n",
        "\n",
        "DATASET_PATH = './'"
      ],
      "metadata": {
        "id": "auniWMCtYHHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data sets and data loaders"
      ],
      "metadata": {
        "id": "wUZvv8UBSCJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We look at the size of the training dataset and grab a batch of size 50"
      ],
      "metadata": {
        "id": "xDQWNfq8xRcm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # Image example and corresponding label\n",
        " print(loader.get_train_size())\n",
        " (images, labels) = loader.get_batch(50)"
      ],
      "metadata": {
        "id": "c1PUTftuThal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Displaying images to get a sense of what the training data actually looks like."
      ],
      "metadata": {
        "id": "LD1xl232xhFN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Examining the data"
      ],
      "metadata": {
        "id": "4VNwFY8wxo89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining architecture"
      ],
      "metadata": {
        "id": "1Irwv40-dMja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvBlock(nn.Module):\n",
        "  \"\"\"Create a standard convolutional block\"\"\"\n",
        "  def __init__(self,in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
        "    super().__init__()\n",
        "    self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, strid, padding)\n",
        "    self.relu = nn.ReLU()\n",
        "    #self.bn = nn.BatchNorm2d(out_channels)\n",
        "    self.maxpool = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "  def forward(self,x)\n",
        "    # block 1\n",
        "    x = self.conv(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.maxpool(x)\n",
        "    return x\n",
        "\n",
        "n_filters =   # base number of convolutional filters\n",
        "in_channels = images.shape[1]\n",
        "\n",
        "\n",
        "model = nn.Sequential(\n",
        "    # base (performs feature extraction)\n",
        "    ConvBlock(in_channels, out_channels, kernel_size=3),\n",
        "    ConvBlock(),\n",
        "    ConvBlock(),\n",
        "    nn.Flatten(),\n",
        "\n",
        "    # head (performs classification)\n",
        "    nn.Linear()\n",
        "    nn.ReLU()\n",
        "    nn.Dropout(0.3)\n",
        "    nn.Linear(,n_outputs)\n",
        "\n",
        ")\n",
        "\n",
        "model.to(device)    # uploading the model to the device"
      ],
      "metadata": {
        "id": "w5BD1aTmTv-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initiate models"
      ],
      "metadata": {
        "id": "Q1MW5K6Zc4hv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "# training hyperparameters\n",
        "params = dict(\n",
        "    batch_size=32,\n",
        "    num_epochs= 5,\n",
        "    learning_rate = ...\n",
        ")\n",
        "\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=params[\"learning_rate\"])    # defining the optimzer\n",
        "loss_history = mdl.util.LossHistory(smoothing_factor=0.99)    # record loss evolution\n",
        "#plotter = mdl.util.PeriodicPlotter(sec=2, scale=\"semilogy\")    # uncomment to see the results while training\n",
        "#optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n"
      ],
      "metadata": {
        "id": "IHq7c7ROfjhk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "R3RHq852fqt0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set the model to train mode\n",
        "model.train()\n",
        "\n",
        "def train_step(x,y):\n",
        "  x = torch.from_numpy(x).float().to(device)\n",
        "  y = torch.from_numpy(y).float().to(device)\n",
        "\n",
        "  # clear the gradients\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  # feed images into the model\n",
        "  logits = model(x)\n",
        "  # compute the loss\n",
        "  loss = loss_fn(logits,y)\n",
        "\n",
        "  # backpropagation\n",
        "  loss.backward()\n",
        "  # update wieghts using grads\n",
        "  optimizer.step\n",
        "\n",
        "  return loss\n",
        "\n",
        "# The training loop\n",
        "\n",
        "step = 0\n",
        "for epoch in range(params[\"num_epochs\"]):\n",
        "  UNDERSTAND tqdm...\n",
        "  # iterate over the batches\n",
        "  for idx in tqdm(range(loader.get_train_size()// params[\"batch_size\"])):\n",
        "    x, y = loader.get_batch(params[\"batch_size\"])\n",
        "    loss = train_step(x, y)\n",
        "    # convert the loss into a NumPy ndarray.\n",
        "    loss_value = loss.detach().cpu().numpy()\n",
        "\n",
        "    # record the loss and plot the evolution of the loss as a function of the training\n",
        "    loss_history.append(loss_value)\n",
        "    #plotter.plot(loss_history.get())  # uncomment to see the updating results live"
      ],
      "metadata": {
        "id": "RYBD0v7xfunY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Accuracy\n",
        "EVALUATE ANOTHER METRIC OF PERFORMACE OTHER THAN THE LOSS....\n",
        "CHECK FOR UNDERFITTING AND OVERFITTING, HOW DO YOU PRESTOP IN PYTORCH"
      ],
      "metadata": {
        "id": "ozl0b0xM74pt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "hwIhQmc-ij3c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "\n",
        "optimizer.zero_grad()  # clear old gradients\n",
        "predictions = model(data) # forward pass\n",
        "loss = criterion(predictions, labels)  # evaluate loss\n",
        "iter_loss += loss.item()  # accumulated loss\n",
        "loss.backward()   # backpropagation: accumulate grads in .grad\n",
        "optimizer.step()  # update wieghts using grads\n",
        "\n",
        "\n",
        "# Plot and save\n",
        "plt.figure(figsize=)\n",
        "plt.clf() ???\n",
        "plt.plot(epochs, train_loss, label='Train')\n",
        "plt.plot(epochs, train_loss, label='Test')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.title('Cross entropy loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.savefig(...)\n",
        "\n",
        "\n",
        "plt.figure(figsize=)\n",
        "plt.clf() ???\n",
        "plt.plot(epochs, train_accuracy, label='Train')\n",
        "plt.plot(epochs, train_accuracy, label='Test')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.savefig(...)"
      ],
      "metadata": {
        "id": "-4XYXrcRimOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results"
      ],
      "metadata": {
        "id": "_Z-Xc0Aej-8O"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JbnXuFVokCA-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}