{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPfuUvb4stu6ABdSrXmmIop",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rda12345/Dam-recognition-classification/blob/main/simple_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Overview\n",
        "\n",
        "The file contains a simple convolutional neural network for ....\n",
        "\n",
        "The convnet is trained on ...\n"
      ],
      "metadata": {
        "id": "l_TMPdbckwq4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j3or0LF2lQV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lagl4TeOFRv2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Import torch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "#import torch.nn.functional F\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "# Orginize outputs\n",
        "#if not os.path.exists('./outputs'):\n",
        "  #os.mkdir('./outputs')\n",
        "\n",
        "# Check that we are using GPU, if not switch runtimes\n",
        "# using Runtime > Change Runtime Type > GPU\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "\n",
        "  # IMPORTANT: cudnn will benchmark different algos. for convolution operations\n",
        "  # and select the on that performs the best for the hardwhare and input size.\n",
        "  # It is usefull when the input sizes are fixed or static during training and inference.\n",
        "  # It isn't benificial when the input sizes change, which would force cudnn to rebenchmark.\n",
        "  #cudnn.benchmark = True\n",
        "\n",
        "else:\n",
        "  raise ValueError(\"GPU is not available. Change Colab runtime\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Global parameters\n",
        "\n",
        "# If USE_CUDA = True, computation will be done using GPU\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "\n",
        "DATASET_PATH = './'\n",
        "BATCH_SIZE = # number of images used to evaluate the gradient in a single step\n",
        "EPOCHS = # number of cycles through the whole data\n",
        "LEARNING_RATE = #"
      ],
      "metadata": {
        "id": "auniWMCtYHHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data sets and data loaders"
      ],
      "metadata": {
        "id": "wUZvv8UBSCJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We look at the size of the training dataset and grab a batch of size 50"
      ],
      "metadata": {
        "id": "xDQWNfq8xRcm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # Image example and corresponding label\n",
        " number_of_training_examples = loader.get_train_size()\n",
        " (images, labels) = loader.get_batch(50)"
      ],
      "metadata": {
        "id": "c1PUTftuThal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Displaying images to get a sense of what the training data actually looks like."
      ],
      "metadata": {
        "id": "LD1xl232xhFN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Examining the data"
      ],
      "metadata": {
        "id": "4VNwFY8wxo89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining architecture"
      ],
      "metadata": {
        "id": "1Irwv40-dMja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvBlock(nn.Module):\n",
        "  \"\"\"Create a standard convolutional block\"\"\"\n",
        "  def __init__(self,in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
        "    super().__init__()\n",
        "    self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, strid, padding)\n",
        "    self.relu = nn.ReLU()\n",
        "    #self.bn = nn.BatchNorm2d(out_channels)\n",
        "    self.maxpool = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "  def forward(self,x)\n",
        "    # block 1\n",
        "    x = self.conv(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.maxpool(x)\n",
        "    return x\n",
        "\n",
        "n_filters =   # base number of convolutional filters\n",
        "in_channels = images.shape[1]\n",
        "\n",
        "\n",
        "model = nn.Sequential(\n",
        "    # base (performs feature extraction)\n",
        "    ConvBlock(in_channels, out_channels, kernel_size=3),\n",
        "    ConvBlock(),\n",
        "    ConvBlock(),\n",
        "    nn.Flatten(),\n",
        "\n",
        "    # head (performs classification)\n",
        "    nn.Linear()\n",
        "    nn.ReLU()\n",
        "    nn.Dropout(0.3)\n",
        "    nn.Linear(,n_outputs)\n",
        "\n",
        ")\n",
        "\n",
        "model.to(device)    # uploading the model to the device"
      ],
      "metadata": {
        "id": "w5BD1aTmTv-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initiate models"
      ],
      "metadata": {
        "id": "Q1MW5K6Zc4hv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNN()\n",
        "if USE_CUDA:\n",
        "  model = model.cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.adam(model.parameters())\n",
        "???\n",
        "#optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "schedular = ????"
      ],
      "metadata": {
        "id": "IHq7c7ROfjhk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "R3RHq852fqt0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NOT AT ALL COMPLETE\n",
        "iter_loss = 0.0\n",
        "model.train()   # put the network into training mode\n",
        "\n",
        "if USE_CUDA:\n",
        "  data = data.cuda()\n",
        "  labels = labels.cuda()\n",
        "\n",
        "\n",
        "optimizer.zero_grad()  # clear old gradients\n",
        "predictions = model(data) # forward pass\n",
        "loss = criterion(predictions, labels)  # evaluate loss\n",
        "iter_loss += loss.item()  # accumulated loss\n",
        "loss.backward()   # backpropagation: accumulate grads in .grad\n",
        "optimizer.step()  # update wieghts using grads"
      ],
      "metadata": {
        "id": "RYBD0v7xfunY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "hwIhQmc-ij3c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()  # put the network into evaluation mode\n",
        "\n",
        "if USE_CUDA:\n",
        "  data = data.cuda()\n",
        "  labels = labels.cuda()\n",
        "\n",
        "\n",
        "optimizer.zero_grad()  # clear old gradients\n",
        "predictions = model(data) # forward pass\n",
        "loss = criterion(predictions, labels)  # evaluate loss\n",
        "iter_loss += loss.item()  # accumulated loss\n",
        "loss.backward()   # backpropagation: accumulate grads in .grad\n",
        "optimizer.step()  # update wieghts using grads\n",
        "\n",
        "\n",
        "# Plot and save\n",
        "plt.figure(figsize=)\n",
        "plt.clf() ???\n",
        "plt.plot(epochs, train_loss, label='Train')\n",
        "plt.plot(epochs, train_loss, label='Test')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.title('Cross entropy loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.savefig(...)\n",
        "\n",
        "\n",
        "plt.figure(figsize=)\n",
        "plt.clf() ???\n",
        "plt.plot(epochs, train_accuracy, label='Train')\n",
        "plt.plot(epochs, train_accuracy, label='Test')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.savefig(...)"
      ],
      "metadata": {
        "id": "-4XYXrcRimOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results"
      ],
      "metadata": {
        "id": "_Z-Xc0Aej-8O"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JbnXuFVokCA-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}